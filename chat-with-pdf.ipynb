{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ : bool = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "client : OpenAI = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "available_functions = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "avalible_tools = [{\"type\": \"retrieval\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Class to Manage All Open API Assistant Calls and Functions\n",
    "from openai.types.beta.threads import Run, ThreadMessage\n",
    "from openai.types.beta.thread import Thread\n",
    "from openai.types.beta.assistant_create_params import Tool\n",
    "\n",
    "import time\n",
    "import json\n",
    "\n",
    "class PDFChatManager:\n",
    "    def __init__(self, model: str = \"gpt-3.5-turbo-1106\"):\n",
    "        self.client = OpenAI()\n",
    "        self.model = model\n",
    "        self.assistant = None\n",
    "        self.thread = None\n",
    "        self.run = None\n",
    "\n",
    "    def create_file(self, file_path: str, purpose: str='assistants') -> None:\n",
    "        with open(file_path, \"rb\") as file:\n",
    "            file_obj = self.client.files.create(file=file, purpose=purpose)\n",
    "            self.file_id = file_obj.id\n",
    "\n",
    "    def create_assistant(self, name: str, instructions: str, tools: list[Tool]) -> None:\n",
    "        self.assistant = self.client.beta.assistants.create(\n",
    "            name=name,\n",
    "            instructions=instructions,\n",
    "            tools=tools,\n",
    "            model=self.model,\n",
    "            file_ids=[self.file_id]\n",
    "        )\n",
    "\n",
    "    def create_thread(self) -> Thread:\n",
    "        self.thread = self.client.beta.threads.create()\n",
    "        return self.thread\n",
    "\n",
    "    def add_message_to_thread(self, role: str, content: str) -> None:\n",
    "        self.client.beta.threads.messages.create(\n",
    "            thread_id=self.thread.id,\n",
    "            role=role,\n",
    "            content=content\n",
    "        )\n",
    "\n",
    "    def run_assistant(self, instructions: str) -> Run:\n",
    "        self.run = self.client.beta.threads.runs.create(\n",
    "            thread_id=self.thread.id,\n",
    "            assistant_id=self.assistant.id,\n",
    "            instructions=instructions\n",
    "        )\n",
    "        return self.run\n",
    "\n",
    "    def wait_for_completion(self, run: Run, thread: Thread) -> Run:\n",
    "\n",
    "        while run.status in [\"in_progress\", \"queued\"]:\n",
    "            run_status = self.client.beta.threads.runs.retrieve(\n",
    "                thread_id=self.thread.id,\n",
    "                run_id=self.run.id\n",
    "            )\n",
    "            print(f\"Run is {run.status} ...\")\n",
    "            time.sleep(3)  # Wait for 3 seconds before checking again\n",
    "\n",
    "            if run_status.status == 'completed':\n",
    "                processed_response = self.process_messages()\n",
    "                return processed_response\n",
    "                # break\n",
    "            elif run_status.status == 'requires_action':\n",
    "                print(\"Function Calling ...\")\n",
    "                self.call_required_functions(run_status.required_action.submit_tool_outputs.model_dump())\n",
    "            elif run.status == \"failed\":\n",
    "                print(\"Run failed.\")\n",
    "                break\n",
    "            else:\n",
    "                print(f\"Waiting for the Assistant to process...: {run.status}\")\n",
    "\n",
    "    def process_messages(self) -> list[ThreadMessage]:\n",
    "        messages: list[ThreadMessage] = self.client.beta.threads.messages.list(thread_id=self.thread.id)\n",
    "        return messages\n",
    "\n",
    "    def call_required_functions(self, required_actions: dict):\n",
    "        tool_outputs = []\n",
    "\n",
    "        for action in required_actions[\"tool_calls\"]:\n",
    "            function_name = action['function']['name']\n",
    "            arguments = json.loads(action['function']['arguments'])\n",
    "            print('function_name', function_name)\n",
    "            print('function_arguments', arguments)\n",
    "\n",
    "            if function_name in available_functions:\n",
    "                    function_to_call = available_functions[function_name]\n",
    "                    output = function_to_call(**arguments)\n",
    "                    tool_outputs.append({\n",
    "                        \"tool_call_id\": action['id'],\n",
    "                        \"output\": output,\n",
    "                    })\n",
    "\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown function: {function_name}\")\n",
    "\n",
    "        print(\"Submitting outputs back to the Assistant...\")\n",
    "        self.client.beta.threads.runs.submit_tool_outputs(\n",
    "            thread_id=self.thread.id,\n",
    "            run_id=self.run.id,\n",
    "            tool_outputs=tool_outputs\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Messages and Plot Images in Financial Analysis If ANY\n",
    "\n",
    "import requests\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "def download_and_save_image(file_id: str, save_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Downloads an image from OpenAI using its file ID and saves it to the specified path.\n",
    "\n",
    "    Args:\n",
    "    - file_id (str): The ID of the file to download.\n",
    "    - save_path (str): The path where the image will be saved.\n",
    "\n",
    "    Returns:\n",
    "    - None\n",
    "    \"\"\"\n",
    "    # Construct the URL to download the image\n",
    "    download_url = f\"https://api.openai.com/v1/files/{file_id}/content\"\n",
    "\n",
    "    # Perform the HTTP GET request to download the image\n",
    "    response = requests.get(download_url, headers={\"Authorization\": f\"Bearer {os.environ.get(\"OPENAI_API_KEY\")}\"})\n",
    "\n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Write the image to the specified file\n",
    "        with open(save_path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"Image downloaded and saved to {save_path}\")\n",
    "    else:\n",
    "        print(f\"Failed to download image: HTTP Status Code {response.status_code}\")\n",
    "\n",
    "\n",
    "def pretty_print(messages: list[ThreadMessage]) -> None:\n",
    "    print(\"# Messages\")\n",
    "    for message in messages.data:\n",
    "        role_label = \"User\" if message.role == \"user\" else \"Assistant\"\n",
    "        # Check the type of message content and handle accordingly\n",
    "        for content in message.content:\n",
    "            if content.type == \"text\":\n",
    "                message_content = content.text.value\n",
    "                print(f\"{role_label}: {message_content}\\n\")\n",
    "                print()\n",
    "            elif content.type == \"image_file\":\n",
    "                # Handle image file content, e.g., print the file ID or download the image\n",
    "                image_file_id = content.image_file.file_id\n",
    "                # Define a path to save the image\n",
    "                image_save_path = f\"image_{image_file_id}.png\"\n",
    "                # Download and save the image\n",
    "                print(f\"{role_label}: Image file ID: {image_file_id}\")\n",
    "                download_and_save_image(image_file_id, image_save_path)\n",
    "\n",
    "                # Display the image within Jupyter Notebook\n",
    "                display(Image(filename=image_save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_pdf(file_path: str, assistant_intructions: str, question_to_ask: str) -> ThreadMessage:\n",
    "    pdf_assistant : PDFChatManager = PDFChatManager()\n",
    "\n",
    "    # 00 Create a file\n",
    "    pdf_assistant.create_file(file_path=file_path)\n",
    "\n",
    "    # 01 Create an assistant\n",
    "    pdf_assistant.create_assistant(name=\"PDF Assistant\", instructions=assistant_intructions, tools=avalible_tools)\n",
    "\n",
    "    # 02 Create a thread\n",
    "    pdf_assistant.create_thread()\n",
    "\n",
    "    # 03 Add a message to the thread\n",
    "    pdf_assistant.add_message_to_thread(role=\"user\", content=question_to_ask)\n",
    "\n",
    "    # 04 Run the assistant\n",
    "    run = pdf_assistant.run_assistant(instructions=\"\")\n",
    "\n",
    "    # 05 Wait for the assistant to complete\n",
    "    messages = pdf_assistant.wait_for_completion(run=run, thread=pdf_assistant.thread)\n",
    "\n",
    "    #06 return response to be displayed\n",
    "    return messages\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ASSISTANT_SEED_PROMPT =  \"\"\" \n",
    "\n",
    "You are a specialized AI Assistant who efficiently manages and extracts information from PDF documents. \n",
    "\n",
    "Your role is to assist a diverse range of users, from business professionals to individuals, in navigating and understanding their PDF files. When interacting with users:\n",
    "\n",
    "1. Identify the User's Objective from their Query\n",
    "\n",
    "2. Request Specific Details: Encourage users to be specific about their needs. For instance, if they want to extract data, ask them to define the type of data (like dates, names, financial figures).\n",
    "\n",
    "3. Understand the Context: Inquire about the nature of the document (e.g., financial report, academic paper) to tailor your assistance accordingly.\n",
    "\n",
    "4. Communicate Clearly: Use straightforward, easy-to-understand language in your responses. Avoid technical jargon unless the user is comfortable with it.\n",
    "\n",
    "5. Logical Question Sequencing: If a task requires multiple steps, guide the user through them in a logical order. For example, start with general extraction before moving to specific data points.\n",
    "\n",
    "6. Prepare for Diverse Responses: Be ready to handle a range of user queries and rephrase your questions or guidance based on user feedback.\n",
    "\n",
    "7. Iterate Based on User Feedback: If the user's response indicates misunderstanding, rephrase your guidance or provide additional clarifications.\n",
    "\n",
    "Remember, your goal is to make the user's interaction with their PDFs more efficient and productive, respecting their privacy and time constraints. Don't say I don't know, instead, return you understanding or ask for more information.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_user_input = input(\"What is your question? \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Share Niches Impacts Discussed in Ch 2. And brainstorm 3 startup ideas and their details based on the niches discussed in ch 2\n"
     ]
    }
   ],
   "source": [
    "print(get_user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run is queued ...\n",
      "Waiting for the Assistant to process...: queued\n",
      "Run is queued ...\n",
      "Waiting for the Assistant to process...: queued\n",
      "Run is queued ...\n",
      "Waiting for the Assistant to process...: queued\n",
      "Run is queued ...\n",
      "Waiting for the Assistant to process...: queued\n",
      "Run is queued ...\n",
      "Waiting for the Assistant to process...: queued\n",
      "Run is queued ...\n"
     ]
    }
   ],
   "source": [
    "# Using Assistant\n",
    "\n",
    "answer = chat_with_pdf(file_path=\"the-economic-potential-of-generative-ai-the-next-productivity-frontier-vf.pdf\", assistant_intructions=ASSISTANT_SEED_PROMPT, question_to_ask=get_user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Messages\n",
      "Assistant: In Chapter 2 of the document \"The Economic Potential of Generative AI: The Next Productivity Frontier\", there is an extensive discussion about the transformation of customer operations through generative AI. The report highlights the potential of generative AI to revolutionize the entire customer operations function, improving customer experience and agent productivity through digital self-service and enhancing and augmenting agent skills. The technology has already demonstrated the ability to automate interactions with customers using natural language, resulting in improved issue resolution and reduced handling time while also diminishing agent attrition and requests to speak to managers. Specifically, the document discusses customer self-service interactions, customer-agent interactions, and agent self-improvement, outlining how generative AI can positively impact each of these areas【11†source】.\n",
      "\n",
      "Based on this analysis, the following startup ideas can be brainstormed:\n",
      "\n",
      "1. **AI-Powered Customer Support Automation Platform**\n",
      "   - This platform could focus on developing human-like chatbots powered by generative AI to deliver immediate personalized responses to complex inquiries. The startup could offer solutions for businesses looking to enhance their customer service operations through AI-driven self-service interactions, automated call scripts for human agents, and real-time assistance during phone conversations. The platform could also provide tools for agent self-improvement, such as summarization of conversations, personalized insights, and tailored follow-up messages.\n",
      "\n",
      "2. **Real-Time Customer Data Retrieval and Assistance Tool**\n",
      "   - A startup could develop a software tool that utilizes generative AI to instantly retrieve customer data, enabling human customer service representatives to more effectively answer questions and resolve issues during initial interactions. The tool could focus on reducing response time and enhancing sales by providing assistance in real time and recommending next steps based on customer data and browsing histories.\n",
      "\n",
      "3. **Personalized Customer Interaction Enhancement Platform**\n",
      "   - This startup could specialize in providing generative AI-powered solutions to enhance the quality and effectiveness of customer interactions. By automating responses to a higher percentage of customer inquiries and resolving issues during initial contact, the platform could significantly improve the overall customer experience. Additionally, it could focus on enhancing sales by rapidly processing customer data and identifying product suggestions and deals tailored to customer preferences.\n",
      "\n",
      "These startup ideas are inspired by the niches and impacts discussed in Chapter 2 of the document, aiming to leverage generative AI technology to transform customer operations.\n",
      "\n",
      "Do any of these startup ideas resonate with your objectives? Or would you like to explore other niches and impacts discussed in the document for additional startup ideas?\n",
      "\n",
      "\n",
      "User: Share Niches Impacts Discussed in Ch 2. And brainstorm 3 startup ideas and their details based on the niches discussed in ch 2\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pretty_print(answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "devday_openai_12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
